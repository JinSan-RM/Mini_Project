{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1fb6a8a",
   "metadata": {},
   "source": [
    "# Ultralytics YOLO format\n",
    "\n",
    "## 1. Directory\n",
    "\n",
    "```powershell\n",
    "<Custom Dataset Directory>\n",
    "****├── 0.jpg\n",
    "├── 0.txt\n",
    "└── ...\n",
    "```\n",
    "\n",
    "### Split Dataset Directory\n",
    "\n",
    "```powershell\n",
    "rico_yolo\n",
    "├── test\n",
    "│   ├── 0.jpg\n",
    "│   ├── 0.txt\n",
    "│   └── ...\n",
    "├── train\n",
    "│   ├── 2.jpg\n",
    "│   ├── 2.txt\n",
    "│   └── ...\n",
    "└── val\n",
    "    ├── 36.jpg\n",
    "    ├── 36.txt\n",
    "    └── ...\n",
    "```\n",
    "\n",
    "## 2. Annotation\n",
    "\n",
    "```\n",
    "<object-class> <x> <y> <width> <height>\n",
    "```\n",
    "\n",
    "### 예시) 2.txt\n",
    "\n",
    "13 0.5 0.4833984375 0.7944444444444444 0.626171875\n",
    "3 0.5 0.758203125 0.7944444444444444 0.0765625\n",
    "21 0.7875 0.758203125 0.16111111111111112 0.065625\n",
    "6 0.5 0.4451171875 0.7944444444444444 0.549609375\n",
    "21 0.5 0.198046875 0.6777777777777778 0.05546875\n",
    "21 0.35381944444444446 0.2568359375 0.3854166666666667 0.062109375\n",
    "8 0.2013888888888889 0.358984375 0.11666666666666667 0.065625\n",
    "8 0.7986111111111112 0.358984375 0.11666666666666667 0.065625\n",
    "\n",
    "## Dataset File Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30baae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_text = \"\"\"\n",
    "path: /weven/datasets/\n",
    "train: /weven/datasets/Object/train\n",
    "val: /weven/datasets/rico_yolo/val\n",
    "test: /weven/datasets/rico_yolo/test\n",
    "\n",
    "names:\n",
    "    0: 'typo_text',\n",
    "    1: 'typo_price_num',\n",
    "    2: 'typo_price_dollar',\n",
    "    3: 'typo_price_W',\n",
    "    4: 'typo_price_won_en',\n",
    "    5: 'typo_price_won_kr',\n",
    "    6: 'image_photo',\n",
    "    7: 'image_colorBG',\n",
    "    8: 'image_removeBG',\n",
    "    9: 'icon_arrow_left',\n",
    "    10: 'icon_arrow_top',\n",
    "    11: 'icon_arrow_bottom',\n",
    "    12: 'icon_arrow_right',\n",
    "    13: 'icon_video_play',\n",
    "    14: 'icon_SNS_insta',\n",
    "    15: 'icon_SNS_youtube',\n",
    "    16: 'btn_radius',\n",
    "    17: 'btn_ellipse',\n",
    "    18: 'btn_square'\"\"\"\n",
    "\n",
    "with open('/tf/notebook/datasets/data.yaml', 'w') as file:\n",
    "    file.write(yaml_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8095c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 작업 디렉토리\n",
    "\n",
    "'''powershell\n",
    "weven\n",
    "├── datasets\n",
    "│   └── Obejectblock\n",
    "└── notebooks\n",
    "    └── read_rico_dataset.ipynb\n",
    "\n",
    "'''\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae18f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 Training - Preparing  Dataset for YOLO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import functools\n",
    "import itertools\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a94a1",
   "metadata": {},
   "source": [
    "## For parallel computing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6863873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "num_workers = 32  # The number of threads or processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f6f8b7",
   "metadata": {},
   "source": [
    "# mt_executor = concurrent.futures.ThreadPoolExecutor(num_workers)  \n",
    "# Use ThreadPoolExecutor for CPU-bound tasks.\n",
    "# mp_executor = concurrent.futures.ProcessPoolExecutor(num_workers)  \n",
    "# Use ProcessPoolExecutor for I/O-bound tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3547d",
   "metadata": {},
   "source": [
    "#  dataset path settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "screenshots_path = Path('../datasets/Object/~')  # 66261 '.jpg' and '.json'\n",
    "annotations_path = Path('../datasets/Object/~/')  # 66261 '.png' and 'json'\n",
    "\n",
    "image_ids = pd.Series([int(p.stem) for p in screenshots_path.iterdir() if p.suffix == '.json'], name='image_id')\n",
    "image_ids = image_ids.sort_values().reset_index(drop='index')\n",
    "\n",
    "screenshot_paths = [screenshots_path / f'{image_id}.jpg' for image_id in image_ids]\n",
    "annotation_paths = [annotations_path / f'{image_id}.png' for image_id in image_ids]\n",
    "view_hierarchy_json_paths = [screenshots_path / f'{image_id}.json' for image_id in image_ids]\n",
    "annotation_hierarchy_json_paths = [annotations_path / f'{image_id}.json' for image_id in image_ids]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965b090",
   "metadata": {},
   "source": [
    "## Read hierarchy json files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92986973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hierarchy_from_json(json_path):\n",
    "    with open(json_path) as fp:\n",
    "        hierarchy = json.load(fp)\n",
    "        return hierarchy\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(num_workers) as mp_executor:\n",
    "    annotation_hierarchies = mp_executor.map(get_hierarchy_from_json, annotation_hierarchy_json_paths)\n",
    "    annotation_hierarchies = list(annotation_hierarchies)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(num_workers) as mp_executor:\n",
    "    view_hierarchies = mp_executor.map(get_hierarchy_from_json, view_hierarchy_json_paths)\n",
    "    view_hierarchies = list(view_hierarchies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c9f0e",
   "metadata": {},
   "source": [
    "# Get Image sizes (가로, 세로)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imsize(path):\n",
    "    im = Image.open(path)\n",
    "    return im.size\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(num_workers) as mp_executor:\n",
    "    screenshot_sizes = mp_executor.map(get_imsize, screenshot_paths)\n",
    "    screenshot_sizes = list(screenshot_sizes)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(num_workers) as mp_executor:\n",
    "    annotation_sizes = mp_executor.map(get_imsize, annotation_paths)\n",
    "    annotation_sizes = list(annotation_sizes)\n",
    "\n",
    "screenshot_sizes_df = pd.DataFrame(screenshot_sizes, columns=['width', 'height'])\n",
    "annotation_sizes_df = pd.DataFrame(annotation_sizes, columns=['width', 'height'])\n",
    "\n",
    "screenshot_sizes_df.insert(0, 'image_id', image_ids)\n",
    "annotation_sizes_df.insert(0, 'image_id', image_ids)\n",
    "screenshot_sizes_df['ratio'] = screenshot_sizes_df['width'] / screenshot_sizes_df['height']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba561a",
   "metadata": {},
   "source": [
    "# Get useful information from hierarchies\n",
    "\n",
    "## A. From view_hierarchies\n",
    "\n",
    "### 1. root size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_size(hierarchy):\n",
    "    return hierarchy['activity']['root']['rel-bounds']\n",
    "\n",
    "root_sizes = map(get_root_size, view_hierarchies)\n",
    "\n",
    "root_sizes_df = pd.DataFrame(root_sizes, columns=['x1', 'y1', 'x2', 'y2'])\n",
    "root_sizes_df.insert(0, 'image_id', image_ids)\n",
    "root_sizes_df['ratio'] = root_sizes_df['x2'] / root_sizes_df['y2']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359cb7ef",
   "metadata": {},
   "source": [
    "### 2. root classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_classes(hierarchy):\n",
    "    root_class_name = hierarchy['activity']['root']['class']\n",
    "    return root_class_name\n",
    "\n",
    "root_class_names = list(map(get_root_classes, view_hierarchies))\n",
    "pd.Series(root_class_names).value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a546a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## B. From annotaion_hierarchies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_attributes(hierarchy, attribute_name):\n",
    "    uniques = set()\n",
    "\n",
    "    recursive_function = functools.partial(get_unique_attributes, attribute_name=attribute_name)\n",
    "    if type(hierarchy) is list:\n",
    "        uniques_list = map(recursive_function, hierarchy)\n",
    "        uniques |= functools.reduce(lambda x,y: x | y, uniques_list, set())\n",
    "    \n",
    "    if type(hierarchy) is dict:\n",
    "        if attribute_name in hierarchy:\n",
    "            uniques.add(hierarchy[attribute_name])\n",
    "    \n",
    "        if 'children' in hierarchy:\n",
    "            uniques |= recursive_function(hierarchy['children'])\n",
    "    \n",
    "    return uniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c9f07",
   "metadata": {},
   "source": [
    "### 1. componentLabel, 2. iconClass, 3.textButtonClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_component_labels = get_unique_attributes(annotation_hierarchies, 'componentLabel')\n",
    "icon_classes = get_unique_attributes(annotation_hierarchies, 'iconClass')\n",
    "text_button_classes = get_unique_attributes(annotation_hierarchies, 'textButtonClass')\n",
    "\n",
    "all_component_labels = sorted(list(all_component_labels))\n",
    "icon_classes = sorted(list(icon_classes))\n",
    "text_button_classes = sorted(list(text_button_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526fd2a3",
   "metadata": {},
   "source": [
    "# Get bounding boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4dad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_component_and_bounds(hierarchy):\n",
    "    bboxes = []\n",
    "\n",
    "    if 'componentLabel' in hierarchy:\n",
    "        label = hierarchy['componentLabel']\n",
    "        x1, y1, x2, y2 = hierarchy['bounds']\n",
    "        bboxes.append(dict(label=label, x1=x1, y1=y1, x2=x2, y2=y2))\n",
    "\n",
    "    if 'children' in hierarchy:\n",
    "        bboxes += list(itertools.chain.from_iterable(map(get_component_and_bounds, hierarchy['children'])))\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "all_bboxes = list(map(get_component_and_bounds, annotation_hierarchies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b42ff4",
   "metadata": {},
   "source": [
    "# Preprocess dataset\n",
    "\n",
    "### Drop duplicated boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf55a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_bbox_dfs = list(map(lambda x: pd.DataFrame(x).drop_duplicates().reset_index(drop=True), all_bboxes))\n",
    "\n",
    "\n",
    "\n",
    "all_bbox_df = pd.concat(all_bbox_dfs, keys=image_ids, names=['image_id', 'bbox_id'])\n",
    "all_bbox_df = all_bbox_df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd7605",
   "metadata": {},
   "source": [
    "### **Find landscape view (wrong matches)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f19889",
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape_screenshot_df = screenshot_sizes_df[screenshot_sizes_df['ratio'] > 1]\n",
    "landscaped = all_bbox_df.index.isin(landscape_screenshot_df['image_id'], level='image_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7e5b34",
   "metadata": {},
   "source": [
    "### **Find overflowed boxes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2fe435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annotation_sizes = {'width': 1440, 'height': 2560}\n",
    "overflowed = all_bbox_df['x1'] < 0\n",
    "overflowed |= all_bbox_df['y1'] < 0\n",
    "overflowed |= all_bbox_df['x2'] > annotation_sizes['width']\n",
    "overflowed |= all_bbox_df['y2'] > annotation_sizes['height']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac387a",
   "metadata": {},
   "source": [
    "### **Find boxes with 0 or negative values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c381804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "negated = all_bbox_df['x1'] >= all_bbox_df['x2']\n",
    "negated |= all_bbox_df['y1'] >= all_bbox_df['y2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a672cdf",
   "metadata": {},
   "source": [
    "### **Filter out all corrupted boxes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b22690",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_df = all_bbox_df[~(landscaped | overflowed | negated)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa41488",
   "metadata": {},
   "source": [
    "# **Convert to YOLO format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d3591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = pd.Series(list(all_component_labels))\n",
    "class_index = pd.Series(class_index.index.values, index=class_index)\n",
    "\n",
    "\n",
    "\n",
    "yolo_bbox_df = pd.DataFrame({\n",
    "    'label': pd.Series(class_index[bbox_df['label']].values, index=bbox_df.index),\n",
    "    'x': (bbox_df['x1'] + bbox_df['x2']) / 2 / annotation_sizes['width'],\n",
    "    'y': (bbox_df['y1'] + bbox_df['y2']) / 2 / annotation_sizes['height'],\n",
    "    'width': (bbox_df['x2'] - bbox_df['x1']) / annotation_sizes['width'],\n",
    "    'height': (bbox_df['y2'] - bbox_df['y1']) / annotation_sizes['height'],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc7c2d",
   "metadata": {},
   "source": [
    "# Create YOLO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22130d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_yolo_path = Path('tf/datasets/datasets')\n",
    "object_yolo_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a858eb2",
   "metadata": {},
   "source": [
    "### Create txt file for each image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d80ab300",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yolo_bbox_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_id, image_bboxes_df \u001b[38;5;129;01min\u001b[39;00m \u001b[43myolo_bbox_df\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_id\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m     image_bboxes_df\u001b[38;5;241m.\u001b[39mto_csv(object_yolo_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yolo_bbox_df' is not defined"
     ]
    }
   ],
   "source": [
    "for image_id, image_bboxes_df in yolo_bbox_df.groupby('image_id'):\n",
    "    image_bboxes_df.to_csv(object_yolo_path / f'{image_id}.txt', sep=' ', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de56a725",
   "metadata": {},
   "source": [
    "### Create dataset yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "711abeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebook\r\n"
     ]
    }
   ],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "886fa794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# 데이터셋 폴더 경로\n",
    "dataset_path = '/tf/notebook/datasets'\n",
    "train_path = 'train'\n",
    "test_path = 'test'\n",
    "valid_path = 'valid'\n",
    "\n",
    "# train, test, valid 폴더 생성\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "os.makedirs(valid_path, exist_ok=True)\n",
    "\n",
    "# 데이터셋 파일 리스트 생성\n",
    "file_list = os.listdir(dataset_path)\n",
    "\n",
    "# 파일 리스트를 무작위로 섞음\n",
    "random.shuffle(file_list)\n",
    "\n",
    "# 데이터셋을 train:test:valid = 70:15:15로 나눔\n",
    "train_size = int(0.7 * len(file_list))\n",
    "test_size = int(0.15 * len(file_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef09ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# 데이터셋 폴더 경로\n",
    "dataset_path = 'datasets'\n",
    "train_path = 'datasets/train'\n",
    "test_path = 'datasets/test'\n",
    "valid_path = 'datasets/valid'\n",
    "\n",
    "# train, test, valid 폴더 생성\n",
    "os.makedirs(train_path + '/images', exist_ok=True)\n",
    "os.makedirs(train_path + '/labels', exist_ok=True)\n",
    "os.makedirs(test_path + '/images', exist_ok=True)\n",
    "os.makedirs(test_path + '/labels', exist_ok=True)\n",
    "os.makedirs(valid_path + '/images', exist_ok=True)\n",
    "os.makedirs(valid_path + '/labels', exist_ok=True)\n",
    "\n",
    "# 데이터셋 파일 리스트 생성\n",
    "file_list = os.listdir(dataset_path)\n",
    "random.shuffle(file_list)\n",
    "\n",
    "# 데이터셋을 train:test:valid = 70:15:15로 나눔\n",
    "train_size = int(0.7 * len(file_list))\n",
    "test_size = int(0.15 * len(file_list))\n",
    "\n",
    "# train 데이터 복사\n",
    "for filename in file_list[:train_size]:\n",
    "    if filename.endswith('.jpeg'):\n",
    "        image_path = os.path.join(dataset_path, filename)\n",
    "        txt_path = os.path.join(dataset_path, filename.replace('.jpeg', '.txt'))\n",
    "        shutil.copy(image_path, os.path.join(train_path + '/images', filename))\n",
    "        shutil.copy(txt_path, os.path.join(train_path + '/labels', filename.replace('.jpeg', '.txt')))\n",
    "\n",
    "# test 데이터 복사\n",
    "for filename in file_list[train_size:train_size+test_size]:\n",
    "    if filename.endswith('.jpeg'):\n",
    "        image_path = os.path.join(dataset_path, filename)\n",
    "        txt_path = os.path.join(dataset_path, filename.replace('.jpeg', '.txt'))\n",
    "        shutil.copy(image_path, os.path.join(test_path + '/images', filename))\n",
    "        shutil.copy(txt_path, os.path.join(test_path + '/labels', filename.replace('.jpeg', '.txt')))\n",
    "\n",
    "# validation 데이터 복사\n",
    "for filename in file_list[train_size+test_size:]:\n",
    "    if filename.endswith('.jpeg'):\n",
    "        image_path = os.path.join(dataset_path, filename)\n",
    "        txt_path = os.path.join(dataset_path, filename.replace('.jpeg', '.txt'))\n",
    "        shutil.copy(image_path, os.path.join(valid_path + '/images', filename))\n",
    "        shutil.copy(txt_path, os.path.join(valid_path + '/labels', filename.replace('.jpeg', '.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75001253",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train', 'val', 'test']\n",
    "with open('data.yaml', 'w') as f:\n",
    "    for split in splits:\n",
    "        split_path = (object_yolo_path.parent / split).resolve()\n",
    "        f.write(f'{split}: {split_path}\\n')\n",
    "    \n",
    "    num_labels = len(all_component_labels)\n",
    "\n",
    "    f.write('names:\\n')\n",
    "    for index, label in enumerate(all_component_labels):\n",
    "        f.write(f'  {index}: {label}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4cc7a",
   "metadata": {},
   "source": [
    "# Copy screenshot files to object_yolopath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cce262",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids_to_copy = yolo_bbox_df.index.get_level_values('image_id').unique()\n",
    "\n",
    "def copy_image(image_id):\n",
    "    shutil.copy(screenshots_path / f'{image_id}.jpg', rico_yolo_path / f'{image_id}.jpg')\n",
    "    return True\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(num_workers) as mp_executor:\n",
    "    results = list(mp_executor.map(copy_image, image_ids_to_copy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a642f",
   "metadata": {},
   "source": [
    "# Data Split yolo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdaec0d",
   "metadata": {},
   "source": [
    "### 데이터셋 path 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f50f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_yolo_path = Path('../datasets/object_yolo/all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f4e78",
   "metadata": {},
   "source": [
    "# Image Id get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f97ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_ids = map(lambda p :int(p.stem), object_yolo_path.iterdir())\n",
    "all_image_ids = pd.Series(all_image_ids).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa43fe",
   "metadata": {},
   "source": [
    "# Random array create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40bb3d82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_image_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mall_image_ids\u001b[49m)\n\u001b[1;32m      2\u001b[0m seed_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_image_ids' is not defined"
     ]
    }
   ],
   "source": [
    "num_samples = len(all_image_ids)\n",
    "seed_id = 0\n",
    "np.ramdom.sedd(seed_id)\n",
    "random_indices = np.random.choice(num_samples, num_samples, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff347e5a",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee91bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train', 'val', 'test']\n",
    "split_ratio = [0.8, 0.1, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a935acd7",
   "metadata": {},
   "source": [
    "## 랜덤 배열을 비율에 맞추어 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8adbd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.array(split_ratio).cumsum() * num_samples\n",
    "ind = np.floor(ind).astype(int) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f92211b",
   "metadata": {},
   "source": [
    "## split별 id값 얻어내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c917883",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = {\n",
    "    'train': all_image_ids[:ind[0]],\n",
    "    'val': all_image_ids[ind[0]:ind[1]],\n",
    "    'test': all_image_ids[ind[1]:],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1085716",
   "metadata": {},
   "source": [
    "## 각 split 폴더로 복사하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d285bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in splits:\n",
    "    object_yolo_split_path = object_yolo_path.parent / split\n",
    "    object_yolo_split_path.mkdir(exist_ok=True)\n",
    "    for image_id in image_ids[split]:\n",
    "        shutil.copy(object_yolo_path / f'{image_id}.jpg', object_yolo_split_path / f'{image_id}.jpg')\n",
    "        shutil.copy(object_yolo_path / f'{image_id}.txt', object_yolo_split_path / f'{image_id}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72083189",
   "metadata": {},
   "source": [
    "# Docker 환경\n",
    "\n",
    "```powershell\n",
    "docker run -dit --name training_yolo --gpus all --ipc=host --mount type=volume,source=rico,destination=/weven/datasets --mount type=volume,source=runs,destination=/weven/runs ultralytics/ultralytics\n",
    "```\n",
    "\n",
    "- `-d` 컨테이너 백그라운드로 실행\n",
    "- `-it` 터미널 연결\n",
    "- `--gpus all` NVIDIA GPU 연결\n",
    "- `--ipc=host` YOLO Docker 환경 추천 세팅\n",
    "    \n",
    "    > IPC mode에서 Shared memory 관련 세팅인데, 자세히 알 필요는 없어 보인다.\n",
    "    > \n",
    "- `--mount type=volume,source=rico,destination=/weven/datasets` 데이터 관련 볼륨 마운트\n",
    "- `--mount type=volume,source=runs,destination=/weven/runs` 학습 관련 볼륨 마운트\n",
    "    - `runs`라는 이름의 볼륨이 없으면 자동으로 생성된다.\n",
    "- `--name training_yolo` 컨테이너 이름\n",
    "- `ultralytics/ultralytics` YOLOv8 이미지\n",
    "\n",
    "# 작업 디렉토리\n",
    "\n",
    "- `/weven/datasets` 는 `rico` 라는 이름의 Docker volume\n",
    "    - RICO 데이터셋과 전처리 결과가 남아 있다.\n",
    "- `/weven/runs` 는 `runs` 라는 이름의 Docker volume\n",
    "    - 학습 세팅과 결과가 저장될 볼륨\n",
    "\n",
    "```powershell\n",
    "weven\n",
    "├── datasets\n",
    "│   ├── RICO\n",
    "│   └── rico_yolo\n",
    "│       ├── all\n",
    "│       ├── test\n",
    "│       ├── train\n",
    "│       └── val\n",
    "└── runs\n",
    "    ├── configs\n",
    "    │   └── ym_sgd_lr_5e-3_epochs_200.yaml\n",
    "    └── train\n",
    "        └── rico_yolo.yaml\n",
    "```\n",
    "\n",
    "## 학습 데이터셋 연결\n",
    "\n",
    "- `/weven/runs/train` 디렉토리에 `rico_yolo.yaml` 파일을 미리 준비해 놓는다.\n",
    "\n",
    "### rico_yolo.yaml\n",
    "\n",
    "```yaml\n",
    "train: /weven/datasets/rico_yolo/train\n",
    "val: /weven/datasets/rico_yolo/val\n",
    "test: /weven/datasets/rico_yolo/test\n",
    "names:\n",
    "  0: Advertisement\n",
    "  1: Background Image\n",
    "  2: Bottom Navigation\n",
    "  3: Button Bar\n",
    "  4: Card\n",
    "  5: Checkbox\n",
    "  6: Date Picker\n",
    "  7: Drawer\n",
    "  8: Icon\n",
    "  9: Image\n",
    "  10: Input\n",
    "  11: List Item\n",
    "  12: Map View\n",
    "  13: Modal\n",
    "  14: Multi-Tab\n",
    "  15: Number Stepper\n",
    "  16: On/Off Switch\n",
    "  17: Pager Indicator\n",
    "  18: Radio Button\n",
    "  19: Slider\n",
    "  20: Text\n",
    "  21: Text Button\n",
    "  22: Toolbar\n",
    "  23: Video\n",
    "  24: Web View\n",
    "```\n",
    "\n",
    "# YOLOv8 Training Configs\n",
    "\n",
    "- 학습 세팅을 설정 파일 하나로 조절할 수 있어 매우 편하다.\n",
    "- `/weven/runs/configs` 에 학습 세팅을 저장해둔다.\n",
    "\n",
    "### ym_sgd_lr_5e-3_epochs_200.yaml\n",
    "\n",
    "```yaml\n",
    "task: detect\n",
    "mode: train\n",
    "model: yolov8m.pt\n",
    "data: rico_yolo.yaml\n",
    "epochs: 200\n",
    "patience: 3\n",
    "batch: 16\n",
    "workers: 16\n",
    "project: yolov8m\n",
    "name: sgd_lr_5e-3_epochs_200\n",
    "optimizer: SGD\n",
    "lr0: 0.005\n",
    "```\n",
    "\n",
    "- 학습 결과 저장: `/weven/runs/train/{project}/{name}`\n",
    "\n",
    "# Training\n",
    "\n",
    "- 실행 위치: `/weven/runs/train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "925665e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3788554442.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    yolo task=detect mode=train model=yolov8m.pt data=/tf/notebook/datasets/data.yaml epochs=100 imgsz=640\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "yolo task=detect mode=train model=yolov8m.pt data=/tf/notebook/datasets/data.yaml epochs=100 imgsz=640 batch=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "146e9f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.138 available 😃 Update with 'pip install -U ultralytics'\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'\u001b[31m\u001b[1mepoch\u001b[0m' is not a valid YOLO argument. Similar arguments are i.e. ['epochs=100'].\n\n    Arguments received: ['yolo', '-f', '/root/.local/share/jupyter/runtime/kernel-2e827445-0042-4623-9959-9c1b5985f744.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of ('detect', 'segment', 'classify', 'pose')\n                MODE (required) is one of ('train', 'val', 'predict', 'export', 'track', 'benchmark')\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    5. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3508\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[19], line 5\u001b[0m\n    results = model.train(data='data.yaml',\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/usr/local/lib/python3.8/dist-packages/ultralytics/yolo/engine/model.py:368\u001b[0m in \u001b[1;35mtrain\u001b[0m\n    self.trainer = TASK_MAP[self.task][1](overrides=overrides, _callbacks=self.callbacks)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/usr/local/lib/python3.8/dist-packages/ultralytics/yolo/engine/trainer.py:82\u001b[0m in \u001b[1;35m__init__\u001b[0m\n    self.args = get_cfg(cfg, overrides)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/usr/local/lib/python3.8/dist-packages/ultralytics/yolo/cfg/__init__.py:114\u001b[0m in \u001b[1;35mget_cfg\u001b[0m\n    check_cfg_mismatch(cfg, overrides)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ultralytics/yolo/cfg/__init__.py:187\u001b[0;36m in \u001b[0;35mcheck_cfg_mismatch\u001b[0;36m\n\u001b[0;31m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>\u001b[0;36m\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '\u001b[31m\u001b[1mepoch\u001b[0m' is not a valid YOLO argument. Similar arguments are i.e. ['epochs=100'].\n\n    Arguments received: ['yolo', '-f', '/root/.local/share/jupyter/runtime/kernel-2e827445-0042-4623-9959-9c1b5985f744.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of ('detect', 'segment', 'classify', 'pose')\n                MODE (required) is one of ('train', 'val', 'predict', 'export', 'track', 'benchmark')\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    5. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8m.pt')\n",
    "\n",
    "results = model.train(data='data.yaml', \n",
    "                      epoch=100,\n",
    "                     imgsz=640,\n",
    "                     batch=16,\n",
    "                     name='yolov8m_test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcda2e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.138 🚀 Python-3.8.10 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8191MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/tf/notebook/datasets/data.yaml, epochs=100, patience=50, batch=32, imgsz=160, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train7\n",
      "Overriding model.yaml nc=80 with nc=19\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3786697  ultralytics.nn.modules.head.Detect           [19, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25867321 parameters, 25867305 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train7', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /tf/notebook/datasets/train/labels.cache... 606 images, 0 backgr\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /tf/notebook/datasets/valid/labels.cache... 125 images, 0 backgrou\u001b[0m\n",
      "Plotting labels to runs/detect/train7/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000435, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 160 train, 160 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train7\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100      1.44G      1.502      3.897      1.332        340        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.699      0.761      0.681      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100      1.41G     0.6383     0.5895     0.9646        317        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.821      0.949      0.909      0.757\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100      1.55G     0.4596     0.3894     0.8967        297        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.961      0.998      0.991      0.911\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100      1.52G     0.4239     0.3485     0.8828        335        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.987      0.991       0.99      0.965\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      1.52G     0.3921     0.3226     0.8673        304        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.982      0.995      0.993      0.965\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100      1.52G     0.3713     0.3125      0.863        334        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989          1      0.993       0.97\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100      1.52G     0.3663     0.3001     0.8573        337        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.987          1      0.993      0.969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      1.52G     0.3433     0.2845     0.8554        346        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.987          1      0.992      0.955\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100      1.52G     0.3544     0.2754     0.8563        323        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.988      0.998      0.992      0.956\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10/100      1.52G     0.3377      0.275     0.8452        318        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.986          1      0.992      0.977\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100      1.52G     0.3285     0.2616     0.8467        325        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.982      0.981      0.993      0.961\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100      1.52G     0.3111     0.2529      0.839        340        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.968\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100      1.52G     0.3078     0.2455     0.8398        342        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.981      0.979      0.993      0.969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100      1.52G     0.3073     0.2427     0.8363        301        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989          1      0.993      0.983\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100      1.52G     0.2994     0.2376     0.8371        349        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994      0.984\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100      1.52G     0.2892     0.2303     0.8356        357        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100      1.52G     0.2883     0.2291     0.8285        325        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100      1.52G     0.2864     0.2302     0.8308        339        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989          1      0.992      0.982\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100      1.52G     0.2843     0.2315     0.8311        307        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.982          1      0.993      0.967\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100      1.52G     0.2723     0.2191     0.8325        351        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.972\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100      1.52G     0.2726     0.2178     0.8262        356        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.991      0.998      0.994      0.976\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100      1.52G     0.2718     0.2176     0.8279        361        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989          1      0.994      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100      1.52G     0.2666     0.2209     0.8239        307        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100      1.52G     0.2596     0.2099     0.8264        328        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.988      0.992      0.992      0.984\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100      1.52G     0.2554     0.2098     0.8267        322        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994      0.976\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100      1.52G     0.2589     0.2078     0.8242        366        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.986          1      0.993      0.983\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100      1.52G     0.2513     0.2007      0.826        321        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100      1.52G     0.2454     0.1988     0.8248        353        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100      1.52G     0.2465     0.1984     0.8231        344        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100      1.52G     0.2466     0.1962     0.8212        295        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989          1      0.992      0.987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100      1.52G     0.2452     0.1965     0.8258        308        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.982          1      0.991      0.986\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100      1.52G     0.2434     0.1968     0.8209        293        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100      1.52G     0.2444     0.1941     0.8255        311        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989          1      0.993      0.979\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100      1.52G     0.2468     0.1997      0.817        325        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     35/100      1.52G      0.241     0.1972     0.8194        366        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100      1.52G     0.2253     0.1881     0.8228        324        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100      1.52G      0.229     0.1867     0.8207        320        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100      1.52G     0.2272     0.1848      0.819        312        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.983\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100      1.52G     0.2194     0.1827     0.8209        352        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100      1.52G     0.2267     0.1812     0.8188        318        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.984\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100      1.52G     0.2193     0.1806      0.813        313        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100      1.52G     0.2216     0.1811     0.8191        302        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100      1.52G     0.2262       0.18     0.8172        374        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100      1.52G     0.2175      0.175     0.8188        303        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100      1.52G     0.2207     0.1768     0.8205        337        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100      1.52G     0.2157      0.175     0.8118        328        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989          1      0.994       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100      1.52G     0.2154     0.1761      0.815        357        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/100      1.52G     0.2131     0.1735     0.8174        337        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100      1.52G     0.2106     0.1743     0.8174        350        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100      1.52G     0.2067     0.1693     0.8078        343        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100      1.52G     0.2129     0.1751     0.8137        309        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/100      1.52G     0.2091      0.171     0.8153        312        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.988          1      0.993      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/100      1.52G     0.2096     0.1709      0.818        277        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989          1      0.994      0.981\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/100      1.52G     0.2152     0.1747     0.8097        339        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/100      1.52G     0.2022     0.1645     0.8119        307        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/100      1.52G     0.2055     0.1722     0.8138        326        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/100      1.52G      0.208     0.1727     0.8078        379        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.986\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/100       1.5G     0.1976     0.1609     0.8088        322        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989          1      0.992      0.985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/100       1.5G     0.2021     0.1662      0.808        378        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     60/100       1.5G     0.1969     0.1624     0.8146        337        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989      0.998      0.993      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/100       1.5G     0.1879     0.1578     0.8097        349        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/100       1.5G     0.1973     0.1638      0.802        327        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/100       1.5G     0.1971      0.159     0.8078        370        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/100       1.5G     0.1956     0.1581     0.8121        295        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/100       1.5G     0.1921     0.1576     0.8106        296        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/100       1.5G     0.1925     0.1576     0.8068        299        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/100       1.5G     0.1916     0.1557     0.8127        296        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/100       1.5G     0.1937     0.1628     0.8097        363        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/100       1.5G     0.1877      0.153     0.8068        377        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.986      0.999      0.991      0.986\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/100       1.5G     0.1885     0.1555     0.8102        304        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.984          1      0.991      0.985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/100       1.5G     0.1913     0.1538     0.8147        354        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989          1      0.992      0.985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/100       1.5G     0.1835     0.1523     0.8046        301        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619      0.989          1      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/100       1.5G     0.1796     0.1491     0.8067        327        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.991      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/100       1.5G     0.1817     0.1485     0.8097        319        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/100       1.5G     0.1808     0.1498     0.8087        360        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/100       1.5G     0.1801     0.1473     0.7985        379        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/100       1.5G     0.1759     0.1488     0.8055        373        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/100       1.5G     0.1841     0.1496     0.8129        328        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/100       1.5G     0.1821     0.1455     0.8088        309        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/100       1.5G     0.1734     0.1452     0.8078        346        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/100       1.5G     0.1797     0.1477     0.8081        341        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/100       1.5G     0.1786     0.1438     0.8098        351        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/100       1.5G     0.1704     0.1408     0.8104        323        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/100       1.5G     0.1755     0.1443     0.8029        358        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99      0.999      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     85/100       1.5G     0.1746     0.1426     0.8035        391        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/100       1.5G     0.1724     0.1413      0.808        336        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/100       1.5G     0.1674     0.1403     0.8098        323        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.991      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/100       1.5G     0.1705     0.1398     0.8029        299        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.991      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/100       1.5G     0.1741     0.1423     0.8036        332        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/100       1.5G     0.1646     0.1381     0.8073        367        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.991      0.988\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/100       1.5G     0.1998     0.2071     0.7782        149        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/100       1.5G     0.1822     0.1383     0.7773        149        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/100       1.5G     0.1741     0.1354     0.7767        149        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.994      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/100       1.5G     0.1692     0.1287     0.7791        149        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/100       1.5G     0.1774     0.1293     0.7728        150        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.992       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/100       1.5G     0.1719     0.1261     0.7765        146        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/100       1.5G     0.1709     0.1241     0.7797        149        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/100       1.5G     0.1669     0.1202     0.7774        148        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/100       1.5G      0.164     0.1183     0.7799        149        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/100       1.5G     0.1685     0.1185     0.7731        149        160: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.992\n",
      "\n",
      "100 epochs completed in 0.126 hours.\n",
      "Optimizer stripped from runs/detect/train7/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from runs/detect/train7/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating runs/detect/train7/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.138 🚀 Python-3.8.10 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8191MiB)\n",
      "Model summary (fused): 218 layers, 25850761 parameters, 0 gradients, 78.7 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        125        619       0.99          1      0.993      0.992\n",
      "           image_photo        125        619       0.99          1      0.993      0.992\n",
      "Speed: 0.0ms preprocess, 2.6ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!yolo train data=/tf/notebook/datasets/data.yaml model=yolov8m.pt epochs=100 lr0=0.01 imgsz=\n",
    "batch=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdbce16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.8/dist-packages (8.0.132)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.0.138-py3-none-any.whl (605 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.5/605.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (3.7.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (10.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (5.12.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->ultralytics) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->ultralytics) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->ultralytics) (68.0.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->ultralytics) (0.40.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.26.4)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.6)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib>=3.2.2->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->ultralytics) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n",
      "Installing collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.0.132\n",
      "    Uninstalling ultralytics-8.0.132:\n",
      "      Successfully uninstalled ultralytics-8.0.132\n",
      "Successfully installed ultralytics-8.0.138\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2f95662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.138 🚀 Python-3.8.10 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8191MiB)\n",
      "Model summary (fused): 218 layers, 25850761 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\n",
      "image 1/1 /tf/notebook/messageImage_1689833556852.jpg: 64x160 7 image_photos, 51.4ms\n",
      "Speed: 0.5ms preprocess, 51.4ms inference, 1.6ms postprocess per image at shape (1, 3, 64, 160)\n",
      "Results saved to \u001b[1mruns/detect/predict10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!yolo detect predict model=/tf/notebook/runs/detect/train7/weights/best.pt source='/tf/notebook/messageImage_1689833556852.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8061b35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebook\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf6d893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data_preprocess2.ipynb\t\t        study\r\n",
      " datasets\t\t\t        test.jpg\r\n",
      " efficientlearning\t\t        tf\r\n",
      " efficientnetv2_impurity_del_v1.ipynb   tfhub_split_datasets.ipynb\r\n",
      " labelingtest\t\t\t        traindata_Image_augmentation.ipynb\r\n",
      " logo.v1i.yolov8\t\t        weblogo.v1i.yolov8\r\n",
      " logo.v4i.yolov8\t\t        weblogo.v2i.yolov8\r\n",
      " logs\t\t\t\t       'weblogo.v2i.yolov8 (1)'\r\n",
      " messageImage_1689833556852.jpg         yolov8_header.ipynb\r\n",
      " runs\t\t\t\t        yolov8m.pt\r\n",
      " step1\t\t\t\t        yolov8n.pt\r\n",
      " step2\t\t\t\t        연습용끄적임.ipynb\r\n",
      " step2_preprocessing.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d954c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
