{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232d891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\r\n",
      "---------------------------- --------------------\r\n",
      "absl-py                      1.4.0\r\n",
      "anyio                        3.7.1\r\n",
      "argon2-cffi                  21.3.0\r\n",
      "argon2-cffi-bindings         21.2.0\r\n",
      "array-record                 0.4.0\r\n",
      "arrow                        1.2.3\r\n",
      "asttokens                    2.2.1\r\n",
      "astunparse                   1.6.3\r\n",
      "attrs                        23.1.0\r\n",
      "backcall                     0.2.0\r\n",
      "beautifulsoup4               4.12.2\r\n",
      "bleach                       6.0.0\r\n",
      "cachetools                   5.3.1\r\n",
      "certifi                      2022.12.7\r\n",
      "cffi                         1.15.1\r\n",
      "chardet                      4.0.0\r\n",
      "charset-normalizer           3.2.0\r\n",
      "click                        8.1.4\r\n",
      "cmake                        3.26.4\r\n",
      "comm                         0.1.3\r\n",
      "contourpy                    1.1.0\r\n",
      "cycler                       0.10.0\r\n",
      "dbus-python                  1.2.16\r\n",
      "debugpy                      1.6.7\r\n",
      "decorator                    5.1.1\r\n",
      "defusedxml                   0.7.1\r\n",
      "dm-tree                      0.1.8\r\n",
      "etils                        1.3.0\r\n",
      "exceptiongroup               1.1.2\r\n",
      "executing                    1.2.0\r\n",
      "fastjsonschema               2.17.1\r\n",
      "filelock                     3.12.2\r\n",
      "flatbuffers                  23.5.26\r\n",
      "fonttools                    4.40.0\r\n",
      "fqdn                         1.5.1\r\n",
      "gast                         0.4.0\r\n",
      "gitdb                        4.0.10\r\n",
      "GitPython                    3.1.32\r\n",
      "google-auth                  2.21.0\r\n",
      "google-auth-oauthlib         1.0.0\r\n",
      "google-pasta                 0.2.0\r\n",
      "googleapis-common-protos     1.59.1\r\n",
      "grpcio                       1.56.0\r\n",
      "h5py                         3.9.0\r\n",
      "idna                         2.10\r\n",
      "importlib-metadata           6.7.0\r\n",
      "importlib-resources          5.12.0\r\n",
      "ipykernel                    6.24.0\r\n",
      "ipython                      8.12.2\r\n",
      "ipython-genutils             0.2.0\r\n",
      "ipywidgets                   8.0.7\r\n",
      "isoduration                  20.11.0\r\n",
      "jedi                         0.18.2\r\n",
      "Jinja2                       3.1.2\r\n",
      "jsonpointer                  2.4\r\n",
      "jsonschema                   4.18.0\r\n",
      "jsonschema-specifications    2023.6.1\r\n",
      "jupyter                      1.0.0\r\n",
      "jupyter_client               8.3.0\r\n",
      "jupyter-console              6.6.3\r\n",
      "jupyter_core                 5.3.1\r\n",
      "jupyter-events               0.6.3\r\n",
      "jupyter-http-over-ws         0.0.8\r\n",
      "jupyter_server               2.7.0\r\n",
      "jupyter_server_terminals     0.4.4\r\n",
      "jupyterlab-pygments          0.2.2\r\n",
      "jupyterlab-widgets           3.0.8\r\n",
      "keras                        2.13.1\r\n",
      "kiwisolver                   1.4.4\r\n",
      "libclang                     16.0.0\r\n",
      "lit                          16.0.6\r\n",
      "Markdown                     3.4.3\r\n",
      "MarkupSafe                   2.1.3\r\n",
      "matplotlib                   3.7.2\r\n",
      "matplotlib-inline            0.1.6\r\n",
      "mistune                      3.0.1\r\n",
      "mpmath                       1.3.0\r\n",
      "nbclassic                    1.0.0\r\n",
      "nbclient                     0.8.0\r\n",
      "nbconvert                    7.6.0\r\n",
      "nbformat                     5.9.0\r\n",
      "nest-asyncio                 1.5.6\r\n",
      "networkx                     3.1\r\n",
      "notebook                     6.5.4\r\n",
      "notebook_shim                0.2.3\r\n",
      "numpy                        1.24.4\r\n",
      "nvidia-cublas-cu11           11.10.3.66\r\n",
      "nvidia-cuda-cupti-cu11       11.7.101\r\n",
      "nvidia-cuda-nvrtc-cu11       11.7.99\r\n",
      "nvidia-cuda-runtime-cu11     11.7.99\r\n",
      "nvidia-cudnn-cu11            8.5.0.96\r\n",
      "nvidia-cufft-cu11            10.9.0.58\r\n",
      "nvidia-curand-cu11           10.2.10.91\r\n",
      "nvidia-cusolver-cu11         11.4.0.1\r\n",
      "nvidia-cusparse-cu11         11.7.4.91\r\n",
      "nvidia-nccl-cu11             2.14.3\r\n",
      "nvidia-nvtx-cu11             11.7.91\r\n",
      "oauthlib                     3.2.2\r\n",
      "opencv-python                4.8.0.74\r\n",
      "opencv-python-headless       4.8.0.74\r\n",
      "opt-einsum                   3.3.0\r\n",
      "overrides                    7.3.1\r\n",
      "packaging                    23.1\r\n",
      "pandas                       2.0.3\r\n",
      "pandocfilters                1.5.0\r\n",
      "parso                        0.8.3\r\n",
      "pexpect                      4.8.0\r\n",
      "pickleshare                  0.7.5\r\n",
      "Pillow                       10.0.0\r\n",
      "pip                          23.1.2\r\n",
      "pkgutil_resolve_name         1.3.10\r\n",
      "platformdirs                 3.8.0\r\n",
      "prometheus-client            0.17.0\r\n",
      "promise                      2.3\r\n",
      "prompt-toolkit               3.0.39\r\n",
      "protobuf                     4.23.3\r\n",
      "psutil                       5.9.5\r\n",
      "ptyprocess                   0.7.0\r\n",
      "pure-eval                    0.2.2\r\n",
      "pyasn1                       0.5.0\r\n",
      "pyasn1-modules               0.3.0\r\n",
      "pycparser                    2.21\r\n",
      "Pygments                     2.15.1\r\n",
      "PyGObject                    3.36.0\r\n",
      "pyparsing                    2.4.7\r\n",
      "python-apt                   2.0.1+ubuntu0.20.4.1\r\n",
      "python-dateutil              2.8.2\r\n",
      "python-dotenv                1.0.0\r\n",
      "python-json-logger           2.0.7\r\n",
      "pytz                         2023.3\r\n",
      "PyYAML                       6.0\r\n",
      "pyzmq                        25.1.0\r\n",
      "qtconsole                    5.4.3\r\n",
      "QtPy                         2.3.1\r\n",
      "referencing                  0.29.1\r\n",
      "requests                     2.31.0\r\n",
      "requests-oauthlib            1.3.1\r\n",
      "requests-toolbelt            1.0.0\r\n",
      "requests-unixsocket          0.2.0\r\n",
      "rfc3339-validator            0.1.4\r\n",
      "rfc3986-validator            0.1.1\r\n",
      "roboflow                     1.1.1\r\n",
      "rpds-py                      0.8.4\r\n",
      "rsa                          4.9\r\n",
      "scipy                        1.10.1\r\n",
      "seaborn                      0.12.2\r\n",
      "Send2Trash                   1.8.2\r\n",
      "setuptools                   68.0.0\r\n",
      "six                          1.14.0\r\n",
      "smmap                        5.0.0\r\n",
      "sniffio                      1.3.0\r\n",
      "soupsieve                    2.4.1\r\n",
      "stack-data                   0.6.2\r\n",
      "supervision                  0.11.1\r\n",
      "sympy                        1.12\r\n",
      "tensorboard                  2.13.0\r\n",
      "tensorboard-data-server      0.7.1\r\n",
      "tensorflow                   2.13.0\r\n",
      "tensorflow-addons            0.21.0\r\n",
      "tensorflow-datasets          4.9.2\r\n",
      "tensorflow-estimator         2.13.0\r\n",
      "tensorflow-hub               0.13.0\r\n",
      "tensorflow-io-gcs-filesystem 0.32.0\r\n",
      "tensorflow-metadata          1.13.1\r\n",
      "termcolor                    2.3.0\r\n",
      "terminado                    0.17.1\r\n",
      "thop                         0.1.1.post2209072238\r\n",
      "tinycss2                     1.2.1\r\n",
      "toml                         0.10.2\r\n",
      "torch                        2.0.1\r\n",
      "torchvision                  0.15.2\r\n",
      "tornado                      6.3.2\r\n",
      "tqdm                         4.65.0\r\n",
      "traitlets                    5.9.0\r\n",
      "triton                       2.0.0\r\n",
      "typeguard                    2.13.3\r\n",
      "typing_extensions            4.5.0\r\n",
      "tzdata                       2023.3\r\n",
      "ultralytics                  8.0.132\r\n",
      "uri-template                 1.3.0\r\n",
      "urllib3                      2.0.3\r\n",
      "wcwidth                      0.2.6\r\n",
      "webcolors                    1.13\r\n",
      "webencodings                 0.5.1\r\n",
      "websocket-client             1.6.1\r\n",
      "Werkzeug                     2.3.6\r\n",
      "wget                         3.2\r\n",
      "wheel                        0.40.0\r\n",
      "widgetsnbextension           4.0.8\r\n",
      "wrapt                        1.15.0\r\n",
      "zipp                         3.15.0\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "!pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12feba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Ti'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.get_device_name(0)\t#gpu 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba2d885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b356ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU를 사용할 수 있습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU를 사용할 수 있습니다.\")\n",
    "else:\n",
    "    print(\"GPU를 사용할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5f1039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /tf/notebook/messageImage_1689833556852.jpg: 128x320 1 image_photo, 56.2ms\n",
      "Speed: 1.6ms preprocess, 56.2ms inference, 8.0ms postprocess per image at shape (1, 3, 128, 320)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "keys: ['boxes']\n",
      "masks: None\n",
      "names: {0: 'typo_text', 1: 'typo_price_num', 2: 'typo_price_dollar', 3: 'typo_price_W', 4: 'typo_price_won_en', 5: 'typo_price_won_kr', 6: 'image_photo', 7: 'image_colorBG', 8: 'image_removeBG', 9: 'icon_arrow_left', 10: 'icon_arrow_top', 11: 'icon_arrow_bottom', 12: 'icon_arrow_right', 13: 'icon_video_play', 14: 'icon_SNS_insta', 15: 'icon_SNS_youtube', 16: 'btn_radius', 17: 'btn_ellipse', 18: 'btn_square'}\n",
      "orig_img: array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (729, 2354)\n",
      "path: '/tf/notebook/messageImage_1689833556852.jpg'\n",
      "probs: None\n",
      "save_dir: None\n",
      "speed: {'preprocess': 1.5635490417480469, 'inference': 56.2281608581543, 'postprocess': 8.009910583496094}]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/tf/notebook/runs/detect/train14/weights/last.pt')\n",
    "\n",
    "image = '/tf/notebook/messageImage_1689833556852.jpg'\n",
    "\n",
    "predictions = model.predict(image)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "get\n",
    "# for prediction in predictions:\n",
    "#     box_coordinates = prediction[:, :4]\n",
    "#     class_probabilities = prediction[:, 4:]\n",
    "#     #class_labels = prediction['클래스_레이블']\n",
    "    \n",
    "# print(box_coordinates, class_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5fb8724",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'boxes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m box_coordinates \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxes\u001b[49m\u001b[38;5;241m.\u001b[39mtensor[:, :\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(box_coordinates)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'boxes'"
     ]
    }
   ],
   "source": [
    "box_coordinates = predictions.boxes.tensor[:, :4]\n",
    "print(box_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a891c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1 - Box Coordinates: tensor([[385.1505,   2.0778, 910.2239, 729.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과 리스트에서 바운딩 박스 좌표 추출\n",
    "box_coordinates_list = [result.boxes.xyxy for result in predictions]\n",
    "\n",
    "# 예측 결과 리스트의 각 원소에 대한 바운딩 박스 좌표 출력\n",
    "for idx, box_coordinates in enumerate(box_coordinates_list):\n",
    "    print(f\"Prediction {idx+1} - Box Coordinates: {box_coordinates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2e85545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_text_box_inside_image_box(image_box, text_box):\n",
    "    image_x_min, image_y_min, image_x_max, image_y_max = image_box\n",
    "    text_x_min, text_y_min, text_x_max, text_y_max = text_box\n",
    "    \n",
    "    if (text_x_min >= image_x_min and text_y_min >= image_y_min and\n",
    "        text_x_max <= image_x_max and text_y_max <= image_y_max):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_text_on_right(image_box, text_box):\n",
    "    image_x_max, image_y_min, _, image_y_max = image_box\n",
    "    text_x_min, text_y_min, _, text_y_max = text_box\n",
    "\n",
    "    if text_x_min >= image_x_max:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_text_on_left(image_box, text_box):\n",
    "    image_x_min, image_y_min, _, image_y_max = image_box\n",
    "    text_x_max, text_y_min, _, text_y_max = text_box\n",
    "\n",
    "    if text_x_max <= image_x_min:\n",
    "        return True\n",
    "    else:\n",
    "        return False    \n",
    "    \n",
    "def is_text_on_top(image_box, text_box):\n",
    "    image_x_min, image_y_min, image_x_max, _ = image_box\n",
    "    _, text_y_max, _, _ = text_box\n",
    "\n",
    "    if text_y_max <= image_y_min:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_text_on_bottom(image_box, text_box):\n",
    "    image_x_min, _, image_x_max, image_y_max = image_box\n",
    "    _, _, _, text_y_min = text_box\n",
    "\n",
    "    if text_y_min >= image_y_max:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def check_text_position(image_box, text_box):\n",
    "    if is_text_box_inside_image_box(image_box, text_box):\n",
    "        return \"Inside\"\n",
    "    elif is_text_on_right(image_box, text_box):\n",
    "        return \"Right\"\n",
    "    elif is_text_on_top(image_box, text_box):\n",
    "        return \"Top\"\n",
    "    elif is_text_on_bottom(image_box, text_box):\n",
    "        return \"Bottom\"\n",
    "    else:\n",
    "        return \"Left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16d2e331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Position: Right\n"
     ]
    }
   ],
   "source": [
    "# 예시 이미지 및 박스 좌표 설정\n",
    "image_box = [0, 0, 800, 600]  # [x_min, y_min, x_max, y_max]\n",
    "text_box = [800, 0, 1200, 500]  # [x_min, y_min, x_max, y_max]\n",
    "\n",
    "# 텍스트 위치 체크\n",
    "result = check_text_position(image_box, text_box)\n",
    "print(\"Text Position:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db363538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_and_image_boxes(results):\n",
    "    data = getModelResult(results)\n",
    "    boxList = data['data']\n",
    "\n",
    "    text_boxes = []\n",
    "    image_boxes = []\n",
    "\n",
    "    for box in boxList:\n",
    "        class_name = box['class_name']\n",
    "        if class_name == 'typo_text':\n",
    "            text_boxes.append(box)\n",
    "        elif class_name in ['image_photo', 'image_colorBG', 'image_removeBG']:\n",
    "            image_boxes.append(box)\n",
    "\n",
    "    return text_boxes, image_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9fd5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getModelResult( results ):\n",
    "    ROOT_PATH = os.getcwd() + \"\\\\\";\n",
    "    data = {}\n",
    "    dataList = []\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Boxes object for bbox outputs\n",
    "        names = result.names\n",
    "        origImg = result.orig_shape\n",
    "        imgWidth = origImg[1]\n",
    "        imgHeight = origImg[0]\n",
    "\n",
    "        data['img_width'] = imgWidth\n",
    "        data['img_height'] = imgHeight\n",
    "        print( origImg )\n",
    "        # masks = result.masks  # Masks object for segmenation masks outputs\n",
    "    #     probs = result.probs  # Class probabilities\n",
    "\n",
    "    #     # print(boxes.xywhn)\n",
    "    #     # print(boxes.cls)\n",
    "    #     # print(masks)\n",
    "    #     # print(probs)\n",
    "        boxList = []\n",
    "        for box in boxes:\n",
    "\n",
    "            boxData = {}\n",
    "            # box.xyxy[0]\n",
    "            \n",
    "            boxResult = box.xywhn.tolist()[0]\n",
    "            classNum = int(box.cls.tolist()[0])\n",
    "            className = names[classNum]\n",
    "            conf = box.conf.tolist()[0]\n",
    "            centerX = boxResult[0]\n",
    "            centerY = boxResult[1]\n",
    "            width = boxResult[2]\n",
    "            height = boxResult[3]\n",
    "\n",
    "            left = centerX - ( width / 2 )\n",
    "            top = centerY - ( height / 2 )\n",
    "\n",
    "            minX = left\n",
    "            minY = top\n",
    "            maxX = left + width\n",
    "            maxY = top + height\n",
    "\n",
    "            boxData['class_name'] = className\n",
    "            boxData['class_id'] = classNum\n",
    "            boxData['confidence'] = conf\n",
    "            boxData['center_x'] = centerX\n",
    "            boxData['center_y'] = centerY\n",
    "            boxData['left'] = left\n",
    "            boxData['top'] = top\n",
    "            boxData['width'] = width\n",
    "            boxData['height'] = height\n",
    "            boxData['minX'] = minX\n",
    "            boxData['minY'] = minY\n",
    "            boxData['maxX'] = maxX\n",
    "            boxData['maxY'] = maxY\n",
    "\n",
    "\n",
    "            boxData['origin_center_x'] = centerX * imgWidth\n",
    "            boxData['origin_center_y'] = centerY * imgHeight\n",
    "            boxData['origin_left'] = left * imgWidth\n",
    "            boxData['origin_top'] = top * imgHeight\n",
    "            boxData['origin_width'] = width * imgWidth\n",
    "            boxData['origin_height'] = height * imgHeight\n",
    "            boxData['origin_minX'] = minX * imgWidth\n",
    "            boxData['origin_minY'] = minY * imgHeight\n",
    "            boxData['origin_maxX'] = maxX * imgWidth\n",
    "            boxData['origin_maxY'] = maxY * imgHeight\n",
    "\n",
    "\n",
    "            # if( boxData['confidence'] * 100 > 60 ):\n",
    "            boxList.append( boxData )\n",
    "        \n",
    "        dataList.append( boxList )\n",
    "    data['data'] = dataList\n",
    "    # jsonStr = json.dumps( dataList )\n",
    "    # print( jsonStr )\n",
    "    return data\n",
    "\n",
    "target_classes = ['typo_text','image_photo', 'image_colorBG', 'image_removeBG'] # 바운딩 박스를 추출하고자 하는 클래스명들의 리스트\n",
    "\n",
    "def extract_boxes_by_class(boxList, target_classes):\n",
    "    target_boxes = []  # target들을 넣을 박스 리스트\n",
    "    for boxListPerImage in boxList:  # 각 이미지 별로 box 정보를 가져옴\n",
    "        for box in boxListPerImage:  # 이미지 내의 모든 박스들을 반복하여 클래스 찾기\n",
    "            class_name = box['class_name']\n",
    "            if class_name in target_classes:\n",
    "                target_boxes.append(box)  # 찾아냈으면 리스트에 추가\n",
    "    return target_boxes\n",
    "\n",
    "\n",
    "\n",
    "def get_text_and_image_boxes(results):\n",
    "    boxList = results['data'][0]  # 'data' 리스트 안에 각 이미지의 바운딩 박스 정보가 들어있으므로 첫 번째 항목을 선택합니다.\n",
    "    text_boxes = extract_boxes_by_class(boxList, ['typo_text'])\n",
    "    image_boxes = extract_boxes_by_class(boxList, ['image_photo', 'image_colorBG', 'image_removeBG'])\n",
    "    return text_boxes, image_boxes\n",
    "\n",
    "\n",
    "def is_box_inside_image(text_boxes, image_boxes):                               # image label안에 text label이 있는지 체크\n",
    "    \n",
    "\n",
    "    for text_box in text_boxes:                                                 \n",
    "        text_x_min, text_y_min, text_x_max, text_y_max = text_box \n",
    "        for image_box in image_boxes:\n",
    "            image_x_min, image_y_min, image_x_max, image_y_max = image_box                                                 \n",
    "            if not (text_x_min >= image_x_min and text_y_min >= image_y_min and\n",
    "                    text_x_max <= image_x_max and text_y_max <= image_y_max):\n",
    "                return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def text_on_right_image(image_boxes, text_boxes):                               # 텍스트가 image 오른쪽에 있는지 체크\n",
    "\n",
    "    for text_box in text_boxes:                                                 \n",
    "        text_x_min, _, _, _ = text_box\n",
    "        for image_box in image_boxes:\n",
    "            image_x_max, _, _, _ = image_box   \n",
    "        if text_x_min >= image_x_max:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def text_on_left_image(image_boxes, text_boxes):                                # 텍스트가 image 왼쪽에 있는지 체크\n",
    "    \n",
    "    for text_box in text_boxes:\n",
    "        _, text_x_max, _, _ = text_box\n",
    "        for image_box in image_boxes:\n",
    "            image_x_min, _, _, _ = image_box\n",
    "            if text_x_max <= image_x_min:\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def text_on_bottom_image(image_boxes, text_boxes):                              # 텍스트가 image 아래쪽에 있는지 체크\n",
    "    \n",
    "    for text_box in text_boxes:\n",
    "        _, _, _, text_y_min = text_box\n",
    "        for image_box in image_boxes:\n",
    "            _, _, _, image_y_max = image_box\n",
    "            if text_y_min >= image_y_max:\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "                                                                                # 어느방향에 있는지 한번에 체크\n",
    "def check_text_position(image_boxes, text_boxes):                               \n",
    "    if is_box_inside_image(image_boxes, text_boxes):\n",
    "        return \"Image Inside Text\"\n",
    "    elif text_on_right_image(image_boxes, text_boxes):\n",
    "        return \"Image Right Text\"\n",
    "    elif text_on_left_image(image_boxes, text_boxes):\n",
    "        return \"Image Left Text\"\n",
    "    elif text_on_bottom_image(image_boxes, text_boxes):\n",
    "        return \"Image Bottom Text\"\n",
    "    else:\n",
    "        return \"Image and Texts are not related\"\n",
    "    \n",
    "def get_min_max_coordinates(data):\n",
    "    min_max_coordinates = []\n",
    "    for image_boxes in data['data']:\n",
    "        for box in image_boxes:\n",
    "            minX = box['minX']\n",
    "            minY = box['minY']\n",
    "            maxX = box['maxX']\n",
    "            maxY = box['maxY']\n",
    "            min_max_coordinates.append((minX, minY, maxX, maxY))\n",
    "    return min_max_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08a8f7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /tf/notebook/messageImage_1689833556852.jpg: 128x320 1 image_photo, 33.2ms\n",
      "Speed: 0.6ms preprocess, 33.2ms inference, 1.8ms postprocess per image at shape (1, 3, 128, 320)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/tf/notebook/runs/detect/train14/weights/last.pt')\n",
    "\n",
    "image = '/tf/notebook/messageImage_1689833556852.jpg'\n",
    "\n",
    "results = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d491cf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /tf/notebook/messageImage_1689833556852.jpg: 128x320 1 image_photo, 8.6ms\n",
      "Speed: 0.6ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 128, 320)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 2354)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     data \u001b[38;5;241m=\u001b[39m getModelResult([result])  \u001b[38;5;66;03m# getModelResult 함수는 리스트를 입력받으므로 현재 result를 리스트로 변환하여 호출\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     boxlist \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# 'data' 리스트 안에 각 이미지의 바운딩 박스 정보가 들어있으므로 첫 번째 항목을 선택합니다.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     extracted_boxes \u001b[38;5;241m=\u001b[39m \u001b[43mextract_boxes_by_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     extracted_boxes_list\u001b[38;5;241m.\u001b[39mappend(extracted_boxes)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# get_text_and_image_boxes 함수 호출\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[42], line 89\u001b[0m, in \u001b[0;36mextract_boxes_by_class\u001b[0;34m(boxList, target_classes)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m boxListPerImage \u001b[38;5;129;01min\u001b[39;00m boxList:  \u001b[38;5;66;03m# 각 이미지 별로 box 정보를 가져옴\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m boxListPerImage:  \u001b[38;5;66;03m# 이미지 내의 모든 박스들을 반복하여 클래스 찾기\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m         class_name \u001b[38;5;241m=\u001b[39m \u001b[43mbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m target_classes:\n\u001b[1;32m     91\u001b[0m             target_boxes\u001b[38;5;241m.\u001b[39mappend(box)  \u001b[38;5;66;03m# 찾아냈으면 리스트에 추가\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/tf/notebook/runs/detect/train14/weights/last.pt')\n",
    "\n",
    "image = '/tf/notebook/messageImage_1689833556852.jpg'\n",
    "\n",
    "results = model.predict(image)\n",
    "\n",
    "# extract_boxes_by_class 함수 호출\n",
    "extracted_boxes_list = []\n",
    "for result in results:\n",
    "    data = getModelResult([result])  # getModelResult 함수는 리스트를 입력받으므로 현재 result를 리스트로 변환하여 호출\n",
    "    boxlist = data['data'][0]  # 'data' 리스트 안에 각 이미지의 바운딩 박스 정보가 들어있으므로 첫 번째 항목을 선택합니다.\n",
    "    extracted_boxes = extract_boxes_by_class(boxlist, target_classes)\n",
    "    extracted_boxes_list.append(extracted_boxes)\n",
    "\n",
    "# get_text_and_image_boxes 함수 호출\n",
    "text_boxes, image_boxes = get_text_and_image_boxes(extracted_boxes_list)\n",
    "print(\"Text Boxes:\", text_boxes)\n",
    "print(\"Image Boxes:\", image_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8a03285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 2354)\n",
      "[[{'class_name': 'image_photo', 'class_id': 6, 'confidence': 0.9632229208946228, 'center_x': 0.27514326572418213, 'center_y': 0.5014250874519348, 'left': 0.16361535340547562, 'top': 0.002850174903869629, 'width': 0.22305582463741302, 'height': 0.9971498250961304, 'minX': 0.16361535340547562, 'minY': 0.002850174903869629, 'maxX': 0.38667117804288864, 'maxY': 1.0, 'origin_center_x': 647.6872475147247, 'origin_center_y': 365.5388887524605, 'origin_left': 385.1505419164896, 'origin_top': 2.0777775049209595, 'origin_width': 525.0734111964703, 'origin_height': 726.922222495079, 'origin_minX': 385.1505419164896, 'origin_minY': 2.0777775049209595, 'origin_maxX': 910.2239531129599, 'origin_maxY': 729.0}]]\n"
     ]
    }
   ],
   "source": [
    "extracted_boxes_list = []\n",
    "for result in results:\n",
    "    data = getModelResult([result])  # getModelResult 함수는 리스트를 입력받으므로 현재 result를 리스트로 변환하여 호출\n",
    "    boxlist = data['data']\n",
    "    extracted_boxes = extract_boxes_by_class(boxlist, target_classes)\n",
    "    extracted_boxes_list.append(extracted_boxes)\n",
    "\n",
    "print(extracted_boxes_list)  # 각 이미지별로 추출된 바운딩 박스 확인|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3119cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes_list(data):\n",
    "    boxes_list = []\n",
    "    for image_boxes in data:\n",
    "        boxes_list.append(image_boxes)\n",
    "    return boxes_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8fe2e254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /tf/notebook/messageImage_1689833556852.jpg: 128x320 1 image_photo, 59.9ms\n",
      "Speed: 1.7ms preprocess, 59.9ms inference, 4.1ms postprocess per image at shape (1, 3, 128, 320)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 2354)\n",
      "['img_width', 'img_height', 'data']\n"
     ]
    }
   ],
   "source": [
    "# getModelResult 함수를 사용하여 결과 데이터 얻기\n",
    "results = model.predict(image)\n",
    "data = getModelResult(results)\n",
    "\n",
    "# 바운딩 박스 정보를 이중 리스트로 추출하기\n",
    "boxes_list = get_boxes_list(data)\n",
    "print(boxes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "473379ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 0.16361535340547562, 0.002850174903869629, 0.38667117804288864, 1.0]\n"
     ]
    }
   ],
   "source": [
    "for i in boxes_list:\n",
    "    for j in i:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "97ed1adf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'boxes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxes\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'boxes'"
     ]
    }
   ],
   "source": [
    "print(results.boxes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31411be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /tf/notebook/messageImage_1689833556852.jpg: 128x320 1 image_photo, 108.1ms\n",
      "Speed: 1.3ms preprocess, 108.1ms inference, 3.6ms postprocess per image at shape (1, 3, 128, 320)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# YOLO 결과를 바탕으로 바운딩 박스 정보 추출\u001b[39;00m\n\u001b[1;32m     40\u001b[0m boxes_list \u001b[38;5;241m=\u001b[39m getModelResult(results)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mboxes_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "def getModelResult(results):\n",
    "    dataList = []\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Boxes object for bbox outputs\n",
    "        names = result.names\n",
    "        origImg = result.orig_shape\n",
    "        imgWidth = origImg[1]\n",
    "        imgHeight = origImg[0]\n",
    "\n",
    "        data = []\n",
    "        for box in boxes:\n",
    "            boxResult = box.xywhn.tolist()[0]\n",
    "            classNum = int(box.cls.tolist()[0])\n",
    "            className = names[classNum]\n",
    "            conf = box.conf.tolist()[0]\n",
    "            centerX = boxResult[0]\n",
    "            centerY = boxResult[1]\n",
    "            width = boxResult[2]\n",
    "            height = boxResult[3]\n",
    "\n",
    "            left = centerX - (width / 2)\n",
    "            top = centerY - (height / 2)\n",
    "\n",
    "            minX = left\n",
    "            minY = top\n",
    "            maxX = left + width\n",
    "            maxY = top + height\n",
    "\n",
    "            boxData = [classNum, minX, minY, maxX, maxY]\n",
    "            data.append(boxData)\n",
    "\n",
    "        dataList.append(data)\n",
    "\n",
    "    return dataList\n",
    "\n",
    "# YOLO 모델로 이미지 예측 수행\n",
    "results = model.predict(image)\n",
    "\n",
    "# YOLO 결과를 바탕으로 바운딩 박스 정보 추출\n",
    "boxes_list = getModelResult(results)\n",
    "print(boxes_list[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "768928e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "keys: ['boxes']\n",
      "masks: None\n",
      "names: {0: 'typo_text', 1: 'typo_price_num', 2: 'typo_price_dollar', 3: 'typo_price_W', 4: 'typo_price_won_en', 5: 'typo_price_won_kr', 6: 'image_photo', 7: 'image_colorBG', 8: 'image_removeBG', 9: 'icon_arrow_left', 10: 'icon_arrow_top', 11: 'icon_arrow_bottom', 12: 'icon_arrow_right', 13: 'icon_video_play', 14: 'icon_SNS_insta', 15: 'icon_SNS_youtube', 16: 'btn_radius', 17: 'btn_ellipse', 18: 'btn_square'}\n",
      "orig_img: array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (729, 2354)\n",
      "path: '/tf/notebook/messageImage_1689833556852.jpg'\n",
      "probs: None\n",
      "save_dir: None\n",
      "speed: {'preprocess': 2.263307571411133, 'inference': 104.02488708496094, 'postprocess': 4.009485244750977}\n"
     ]
    }
   ],
   "source": [
    "for i in results:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f07f0173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /tf/notebook/202307201123090707.jpg: 160x320 5 image_photos, 45.6ms\n",
      "Speed: 0.7ms preprocess, 45.6ms inference, 1.9ms postprocess per image at shape (1, 3, 160, 320)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1/1\n",
      "Bounding Box Coordinates:\n",
      "tensor([[1087.4695,    1.9572, 1604.9768,  323.3430],\n",
      "        [ 554.8138,    2.1431, 1081.7874,  401.3712],\n",
      "        [1087.3472,  329.1396, 1603.8237,  726.0000],\n",
      "        [  32.6036,    3.8265,  550.2618,  726.0000],\n",
      "        [ 554.5333,  407.4024, 1082.8427,  726.0000]], device='cuda:0')\n",
      "Class IDs:\n",
      "tensor([6., 6., 6., 6., 6.], device='cuda:0')\n",
      "Confidence Scores:\n",
      "tensor([0.9796, 0.9788, 0.9771, 0.9732, 0.9541], device='cuda:0')\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/tf/notebook/runs/detect/train14/weights/last.pt')\n",
    "\n",
    "image = '/tf/notebook/202307201123090707.jpg'\n",
    "\n",
    "results = model.predict(image)\n",
    "\n",
    "# 예측한 바운딩 박스 정보를 출력합니다.\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Image {i+1}/{len(results)}\")\n",
    "    boxes = result.boxes.xyxy\n",
    "    print(\"Bounding Box Coordinates:\")\n",
    "    print(boxes)\n",
    "\n",
    "    class_ids = result.boxes.cls\n",
    "    print(\"Class IDs:\")\n",
    "    print(class_ids)\n",
    "\n",
    "    scores = result.boxes.conf\n",
    "    print(\"Confidence Scores:\")\n",
    "    print(scores)\n",
    "    print(\"--------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3956d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
