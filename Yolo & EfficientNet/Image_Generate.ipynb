{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95e2a11-ce0d-4618-bbfc-67dc87cf0a35",
   "metadata": {},
   "source": [
    "# import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from PIL import Image\n",
    "\n",
    "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
    "\n",
    "# Use the DPMSolverMultistepScheduler (DPM-Solver++) scheduler here instead\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "input_image = Image.open(\"/tf/notebook/dog.jpg\")\n",
    "\n",
    "# 변환을 위한 프롬프트 설정\n",
    "prompt = \"Cute,Retriever\"\n",
    "\n",
    "# 이미지-투-이미지 변환 수행\n",
    "edited_image = pipe(prompt=prompt, init_image=input_image, strength=0.75).images[0]\n",
    "\n",
    "# 결과 이미지 저장\n",
    "edited_image.save(\"edited_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62182f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: invisible_watermark in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.35.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (0.25.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
      "Requirement already satisfied: Pillow>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from invisible_watermark) (10.1.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from invisible_watermark) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from invisible_watermark) (1.26.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.11/dist-packages (from invisible_watermark) (4.8.1.78)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from invisible_watermark) (2.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->invisible_watermark) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->invisible_watermark) (12.3.101)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->invisible_watermark) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->invisible_watermark) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install invisible_watermark transformers accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "url = \"/tf/notebook/dog.jpg\"\n",
    "\n",
    "init_image = load_image(url).convert(\"RGB\")\n",
    "prompt = \"cute, Pomeranian puppy and brown white\"\n",
    "image = pipe(prompt, image=init_image).images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d097b3f1-4cc8-4c68-9f55-166d6f119f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.24.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.35.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (0.25.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.11.4)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (10.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.19.4)\n",
      "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers) (4.6.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (1.26.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.1.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers) (2023.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install diffusers transformers accelerate scipy safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1897146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "# pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "#     \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    "# )\n",
    "pipe = StableDiffusionXLImg2ImgPipeline.from_single_file(\"/tf/notebook/majicmixRealistic_v7.safetensors\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# Load the initial image\n",
    "url = \"/tf/notebook/LEEEUNBEE.jpg\"\n",
    "init_image = load_image(url).convert(\"RGB\")\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"A beautiful 18-year-old Korean girl, peacefully asleep with her eyes closed while sitting on a subway. Her face carries a serene expression, with radiant skin and a tranquil demeanor, clothes is wet, shows nipple, she appears to be at ease, as if enjoying a peaceful nap, large breast, without underwear\"\n",
    "\n",
    "# Generate the image\n",
    "generated_image = pipe(prompt, image=init_image).images[0]\n",
    "\n",
    "# Save the generated image\n",
    "output_path = \"/tf/notebook/generate_person.png\"\n",
    "generated_image.save(output_path)\n",
    "\n",
    "# # Display the path for download\n",
    "# output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbebd4-2ddd-4850-8653-84aa55e1e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U autotrain-advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3bdab-3e56-412f-a069-49267da46f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7db1e-b03e-4630-b1a9-1481838c2127",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38838a7-0f26-4e82-a22b-d06904685aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain setup --update-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13558f4b-ad8e-440e-9400-0e80cfc2c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_name = 'stabilityai/stable-diffusion-xl-base-1.0'\n",
    "prompt =  \"A beautiful 18-year-old Korean girl, peacefully asleep with her eyes closed while sitting on a subway. Her face carries a serene expression, with radiant skin and a tranquil demeanor, clothes is wet, shows nipple, she appears to be at ease, as if enjoying a peaceful nap, large breast, without underwear\"\n",
    "output_path = \"/tf/notebook/generate_person\"\n",
    "image_path = \"/tf/notebook/LEEEUNBEE.jpg/\" #Need_to_fix_a_keyword\n",
    "\n",
    "learning_rate = 1e-4\n",
    "num_steps = 1000\n",
    "batch_size = 4\n",
    "gradient_accumulation = 4\n",
    "resolution = 1024\n",
    "use_8bit_adam = True\n",
    "use_xformers = True\n",
    "use_fp16 = True\n",
    "train_text_encoder = False\n",
    "gradient_checkpointing = True\n",
    "\n",
    "os.environ[\"MODEL_NAME\"] = model_name\n",
    "os.environ[\"PROJECT_NAME\"] = output_path\n",
    "os.environ[\"PROMPT\"] = prompt\n",
    "os.environ[\"IMAGE_PATH\"] = image_path\n",
    "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
    "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
    "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
    "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
    "os.environ[\"RESOLUTION\"] = str(resolution)\n",
    "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
    "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
    "os.environ[\"USE_FP16\"] = str(use_fp16)\n",
    "os.environ[\"GRADIENT_CHECKPOINTING\"] = str(gradient_checkpointing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50014d3e-c9eb-42f4-a9e8-5f7b8f739d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain dreambooth \\\n",
    "--model ${MODEL_NAME} \\\n",
    "--project-name ${PROJECT_NAME} \\\n",
    "--image-path ${IMAGE_PATH} \\\n",
    "--prompt \"${PROMPT}\" \\\n",
    "--resolution ${RESOLUTION} \\\n",
    "--batch-size ${BATCH_SIZE} \\\n",
    "--num-steps ${NUM_STEPS} \\\n",
    "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
    "--lr ${LEARNING_RATE} \\\n",
    "$( [[ \"$USE_FP16\" == \"True\" ]] && echo \"--fp16\" ) \\\n",
    "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
    "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
    "$( [[ \"$GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--gradient-checkpointing\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b2f488-67b7-426b-af45-a4afed63ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash\n",
    "!autotrain dreambooth \\\n",
    "--model ${MODEL_NAME} \\\n",
    "--project-name ${PROJECT_NAME} \\\n",
    "--image-path ${IMAGE_PATH} \\\n",
    "--prompt \"${PROMPT}\" \\\n",
    "--resolution ${RESOLUTION} \\\n",
    "--batch-size ${BATCH_SIZE} \\\n",
    "--num-steps ${NUM_STEPS} \\\n",
    "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
    "--lr ${LEARNING_RATE} \\\n",
    "$( [ \"$USE_FP16\" = \"True\" ] && echo \"--fp16\" ) \\\n",
    "$( [ \"$USE_XFORMERS\" = \"True\" ] && echo \"--xformers\" ) \\\n",
    "$( [ \"$USE_8BIT_ADAM\" = \"True\" ] && echo \"--use-8bit-adam\" ) \\\n",
    "$( [ \"$GRADIENT_CHECKPOINTING\" = \"True\" ] && echo \"--gradient-checkpointing\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040fd433-bd1e-4712-9229-489dad9bf4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install invisible_watermark transformers accelerate safetensors\n",
    "!pip install git+https://github.com/huggingface/diffusers\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a6b6611-e0d0-4396-ba3b-c2e2eda780f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72d33dc634c489ea9906a3b194f3513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (184 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [\"xiv, a dog and a puppy sitting, a 3 d render by pixar, cgsociety, furry art, official art, movie poster, poster art, pomeranian, a realistic 3 d rendering style image of a dog. the dog is in a lively and expressive pose, with the texture and color of its fur delicately depicted. the image emphasizes depth and dimension through well - balanced light and shadows, with a minimal background to focus on the dog. the camera angle is adjusted to clearly show the dog's face and entire body\"]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (184 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [\"xiv, a dog and a puppy sitting, a 3 d render by pixar, cgsociety, furry art, official art, movie poster, poster art, pomeranian, a realistic 3 d rendering style image of a dog. the dog is in a lively and expressive pose, with the texture and color of its fur delicately depicted. the image emphasizes depth and dimension through well - balanced light and shadows, with a minimal background to focus on the dog. the camera angle is adjusted to clearly show the dog's face and entire body\"]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c51ebe1eb84569a4ca41da2cd0d84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image save\n"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "import torch\n",
    "from diffusers.utils import load_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "model,\n",
    "torch_dtype=torch.float16,variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "pipe.to(\"cuda\")\n",
    "pipe.load_lora_weights(\"/tf/notebook/3D_Animation_Style-000009.safetensors\")\n",
    "# pipe.from_single_file(\"/tf/notebook/nwsj_xl_v2.safetensors\")\n",
    "# refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "# \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
    "# torch_dtype=torch.float16,\n",
    "# )\n",
    "# refiner.to(\"cuda\")\n",
    "\n",
    "url = \"/tf/notebook/KakaoTalk_20231211_125444529_01.jpg\"\n",
    "init_image = load_image(url).convert(\"RGB\")\n",
    "\n",
    "prompt = \"Close-up so that all paws are clearly visible, Adjust the camera angle to highlight the details of the paws,a small white dog, shutterstock contest winner, holography, vaporwave, white background, angelic photograph, tumblr, tachisme, dynamic pose, rendered in unreal engine, stockphoto, pixiv, rococo, booru, stockphoto, pixiv, a dog and a puppy sitting, a 3D render by Pixar, cgsociety, furry art, official art, movie poster, poster art, Pomeranian, A realistic 3D rendering style image of a dog. The dog is in a lively and expressive pose, with the texture and color of its fur delicately depicted. The image emphasizes depth and dimension through well-balanced light and shadows, with a minimal background to focus on the dog. The camera angle is adjusted to clearly show the dog's face and entire body\"\n",
    "negative_prompt = \"ugly, deformed, noisy, blurry, distorted, grainy, text, cropped, black eyebrows\"\n",
    "#for seed in range(10):\n",
    "generator = torch.Generator(\"cuda\").manual_seed(43)\n",
    "image = pipe(prompt=prompt, negative_prompt=negative_prompt, generator=generator, num_inference_steps=40, image=init_image, output_type=\"PIL\" )\n",
    "image = image.images[0]\n",
    "# image = refiner(prompt=prompt, negative_prompt=negative_prompt, generator=generator, image=init_image)\n",
    "# image = image.images[0]\n",
    "\n",
    "output_path = \"/tf/notebook/generate_dog.png\"\n",
    "\n",
    "if isinstance(image, np.ndarray):\n",
    "    image = (255 * image).astype(np.uint8)\n",
    "\n",
    "    # Check the shape of the array and adjust if necessary\n",
    "    # For example, if the shape is not (height, width, channels), reshape it\n",
    "\n",
    "    # Convert NumPy array to PIL Image\n",
    "    img = Image.fromarray(image)\n",
    "else:\n",
    "    # If it's already a PIL image\n",
    "    img = image\n",
    "\n",
    "# Save the image\n",
    "img.save(output_path)\n",
    "print(\"image save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a534054-b571-4a31-a871-f6e6e54b5dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f5499-a7e4-49fd-912b-071c6753e9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A {keyword} man, photorealistic, bold and elegant, close up, sharp expression, look at camera, block noise, vibrant colors, glitchcore, fuzz, color bars, abstract background, pop kei, bold outlines, ultrafine detailed, best quality\"\n",
    "negative_prompt = \"ugly, deformed, noisy, blurry, distorted, grainy, text, cropped\"\n",
    "#for seed in range(10):\n",
    "generator = torch.Generator(\"cuda\").manual_seed(43)\n",
    "image = pipe(prompt=prompt, negative_prompt=negative_prompt, generator=generator, num_inference_steps=40)\n",
    "image = image.images[0]\n",
    "image = refiner(prompt=prompt, negative_prompt=negative_prompt, generator=generator, image=image)\n",
    "image = image.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a77ebe-7567-4ee5-8f2d-134d0e9303fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc2cf58-3563-4bd1-8f2e-10fe6407d119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 01:11:52.830469: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-11 01:11:52.830525: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-11 01:11:52.857092: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-11 01:11:52.923059: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d004d8387e4455b4ff8ed17ff7fa91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3467e213494068897f8ad998b43ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/4.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665917c98de3415994adaef6b54a7b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0e11e419824f698274209cc37f9d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e1013d8f7543609737f70a48a69af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.fp16.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c1f4da0c564855a74a22d535ec3ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'UNet2DConditionModel' object has no attribute ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tf/notebook/FilmVelvia3.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m pipe \u001b[38;5;241m=\u001b[39m StableDiffusionXLImg2ImgPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstabilityai/stable-diffusion-xl-refiner-1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, variant\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_safetensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_attn_procs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m pipe\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# pipeline.enable_xformers_memory_efficient_attention()\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/loaders/unet.py:260\u001b[0m, in \u001b[0;36mUNet2DConditionLoadersMixin.load_attn_procs\u001b[0;34m(self, pretrained_model_name_or_path_or_dict, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m attn_processor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_key \u001b[38;5;129;01min\u001b[39;00m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 260\u001b[0m     attn_processor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(attn_processor, sub_key)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# Process non-attention layers, which don't have to_{k,v,q,out_proj}_lora layers\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# or add_{k,v,q,out_proj}_proj_lora layers.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m rank \u001b[38;5;241m=\u001b[39m value_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlora.down.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:222\u001b[0m, in \u001b[0;36mModelMixin.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_dict[name]\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# call PyTorch's https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'UNet2DConditionModel' object has no attribute ''"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import AutoPipelineForImage2Image, StableDiffusionPipeline\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "model_path = \"/tf/notebook/FilmVelvia3.safetensors\"\n",
    "pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "\n",
    "pipe.unet.load_attn_procs(model_path)\n",
    "pipe.to(\"cuda\")\n",
    "# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\n",
    "# pipeline.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "url = \"/tf/notebook/LEEEUNBEE.jpg\"\n",
    "init_image = load_image(url).convert(\"RGB\")\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"A beautiful 18-year-old Korean girl, peacefully asleep with her eyes closed while sitting on a subway. Her face carries a serene expression, with radiant skin and a tranquil demeanor, clothes is wet, shows nipple, she appears to be at ease, as if enjoying a peaceful nap, large breast, without underwear\"\n",
    "\n",
    "# Generate the image\n",
    "generated_image = pipeline(prompt, image=init_image).images[0]\n",
    "\n",
    "# Save the generated image\n",
    "output_path = \"/tf/notebook/generate_person.png\"\n",
    "generated_image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a32763e-4d29-4146-82aa-028c8d8da790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'a small white dog sitting in a persons lap'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "captioner = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\")\n",
    "captioner(\"/tf/notebook/dog.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fec7158-7246-4654-a54f-d278b8134278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed476147d7e4b93a81e3da4ee239df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49f60acc06848db848f7120e9232557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image save\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e025064-06ae-436e-8b2f-443a5e4b9fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
